{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOsdG9IKNCUELLscqAJzhlI"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "reh9g-Fxthvy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from os import listdir\n",
        "import string\n",
        "from pickle import dump\n",
        "from numpy import argmax, array\n",
        "from pickle import load\n",
        "from itertools import islice\n",
        "\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
        "\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.models import Model\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import load_model\n",
        "from keras.layers import Input, GlobalAveragePooling2D, Dense, Dropout, LSTM, Embedding\n",
        "from keras.utils import to_categorical, plot_model\n",
        "from keras.layers.merge import add\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from nltk.translate.bleu_score import corpus_bleu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b08WaooStnMS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# feature extraction\n",
        "def feature_extraction(directory):\n",
        "\tmodel = VGG16()\n",
        " \t# model = VGG19()\n",
        "\t# model = InceptionV3()\n",
        "\t# model = ResNet50()\n",
        "\t# model = InceptionResNetV2()\n",
        "\t# feature_extractor = InceptionResNetV2(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n",
        "\t# model = feature_extractor.output\n",
        "\t# model = GlobalAveragePooling2D()(model)\n",
        "\t# model = Dropout(0.5)(model)\n",
        "\t# model = Dense(4096, activation=\"relu\")(model)\n",
        "\t# model = Dropout(0.5)(model)\n",
        "\t# model = Dense(4096, activation=\"relu\")(model)\n",
        "\n",
        "\tmodel.layers.pop()\n",
        "\tmodel = Model(inputs=model.inputs, outputs=model.layers[-1].output)\n",
        "\n",
        "\tfeatures = dict()\n",
        "\tfor name in listdir(directory):\n",
        "\t\timg = load_img(directory + '/' + name, target_size=(224, 224))\n",
        "\t\timg = img_to_array(img)\n",
        "\t\timg = img.reshape((1, img.shape[0], img.shape[1], img.shape[2]))\n",
        "\t\timg_id = name.split('.')[0]\n",
        "\t\tfeatures[img_id] = model.predict(preprocess_input(img), verbose=0)\n",
        "\treturn features\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yC5mMoJktqCx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# extracting features and dumping the features into a pickle file\n",
        "directory = 'Flicker8k_Dataset'\n",
        "features = feature_extraction(directory)\n",
        "print('Number of Features Extracted:', len(features))\n",
        "dump(features, open('features.pkl', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sg9ENkEZeRdq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#extracting and cleaning up the descriptions\n",
        "def load_file(name):\n",
        "\tf = open(name, 'r')\n",
        "\ttxt = f.read()\n",
        "\tf.close()\n",
        "\treturn txt\n",
        "\n",
        "\n",
        "def extract_descriptions(file):\n",
        "\td_map = {}\n",
        "\tfor r in file.split('\\n'):\n",
        "\t\tword = r.split()\n",
        "\t\tif len(r) < 2:\n",
        "\t\t\tcontinue\n",
        "\t\timg_id, img_desc = word[0], word[1:]\n",
        "\t\timg_id = img_id.split('.')[0]\n",
        "\t\timg_desc = ' '.join(img_desc)\n",
        "\t\tif img_id not in d_map:\n",
        "\t\t\td_map[img_id] = []\n",
        "\t\td_map[img_id].append(img_desc)\n",
        "\treturn d_map\n",
        "\n",
        "def get_vocab(text):\n",
        "\tdoc = set()\n",
        "\tfor k in text.keys():\n",
        "\t\t[doc.update(txt.split()) for txt in text[k]]\n",
        "\treturn doc\n",
        "\n",
        "def proc_descriptions(text):\n",
        "\tlemma = str.maketrans('', '', string.punctuation)\n",
        "\tfor key, desc_list in text.items():\n",
        "\t\tfor word in range(len(desc_list)):\n",
        "\t\t\tdesc = desc_list[word].split()\n",
        "\t\t\tdesc = [w for w in desc if len(w)>1]\n",
        "\t\t\tdesc = [w.lower() for w in desc]\n",
        "\t\t\tdesc = [w for w in desc if w.isalpha()]\n",
        "\t\t\tdesc = [w.translate(lemma) for w in desc]\n",
        "\t\t\tdesc_list[word] =  ' '.join(desc)\n",
        "\n",
        "\n",
        "def save_desc(text, name):\n",
        "\trow = []\n",
        "\tfor k, txt in text.items():\n",
        "\t\tfor word in txt:\n",
        "\t\t\trow.append(k + ' ' + word)\n",
        "\tlemma = '\\n'.join(row)\n",
        "\tf = open(name, 'w')\n",
        "\tf.write(lemma)\n",
        "\tf.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0q6qlmu0ejqp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenfile = 'Flickr8k_text/Flickr8k.token.txt'\n",
        "# loading token file\n",
        "tokens = load_file(tokenfile)\n",
        "# extracting descriptions\n",
        "descriptions = extract_descriptions(tokens)\n",
        "print('Loaded Descriptions:', len(descriptions))\n",
        "# processing\n",
        "proc_descriptions(descriptions)\n",
        "# creating vocabulary\n",
        "vocab = get_vocab(descriptions)\n",
        "print('Size of Vocabulary:', len(vocab))\n",
        "# saving descriptions file\n",
        "save_desc(descriptions, 'descriptions.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3_ygg1Cfd52",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# view description sample\n",
        "def desc_sample(n, items):\n",
        "    return list(islice(items, n))\n",
        "desc_sample(1, descriptions.items())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVvuA7ChfIIl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the dataset and then creating list of descriptions\n",
        "def dataset_load(name):\n",
        "\tdataset = []\n",
        "\tdata = load_file(name)\n",
        "\tfor row in data.split('\\n'):\n",
        "\t\tif len(row) < 1:\n",
        "\t\t\tcontinue\n",
        "\t\tdataset.append(row.split('.')[0])\n",
        "\treturn set(dataset)\n",
        "\n",
        "def desc_load(name, dataset):\n",
        "\tdata = load_file(name)\n",
        "\tcaptions = {}\n",
        "\tfor row in data.split('\\n'):\n",
        "\t\twords = row.split()\n",
        "\t\timg_id, img_desc = words[0], words[1:]\n",
        "\t\tif img_id in dataset:\n",
        "\t\t\tif img_id not in captions:\n",
        "\t\t\t\tcaptions[img_id] = list()\n",
        "\t\t\tcaptions[img_id].append('capstart ' + ' '.join(img_desc) + ' capend')\n",
        "\treturn captions\n",
        "\n",
        "def img_desc(name, dataset):\n",
        "\tlemma = load(open(name, 'rb'))\n",
        "\tfeatures = {data: lemma[data] for data in dataset}\n",
        "\treturn features\n",
        "\n",
        "def list_desc(captions):\n",
        "\tlemma = []\n",
        "\tfor word in captions.keys():\n",
        "\t\t[lemma.append(token) for token in captions[word]]\n",
        "\treturn lemma\n",
        "\n",
        "def tokenize(captions):\n",
        "\ttoken = Tokenizer()\n",
        "\ttoken.fit_on_texts(list_desc(captions))\n",
        "\treturn token\n",
        "\n",
        "def max_length(captions):\n",
        "\trows = list_desc(captions)\n",
        "\treturn max(len(row.split()) for row in rows)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0by4dKncfMha",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def caption_generator(token, max_length, captions, images, word_count):\n",
        "\tfirst, second, result = [], [], []\n",
        "\tfor key, value in captions.items():\n",
        "\t\tfor val in value:\n",
        "\t\t\tcap = token.texts_to_sequences([val])[0]\n",
        "\t\t\tfor word in range(1, len(cap)):\n",
        "\t\t\t\tins, outs = cap[:word], cap[word]\n",
        "\t\t\t\tins = pad_sequences([ins], maxlen=max_length)[0]\n",
        "\t\t\t\touts = to_categorical([outs], num_classes=word_count)[0]\n",
        "\t\t\t\tfirst.append(images[key][0])\n",
        "\t\t\t\tsecond.append(ins)\n",
        "\t\t\t\tresult.append(outs)\n",
        "\treturn array(first), array(second), array(result)\n",
        "\n",
        "def training_model(word_count, max_length):\n",
        "\tfeature0 = Input(shape=(4096,))\n",
        "\tfeature1 = Dropout(0.5)(feature0)\n",
        "\tfeature2 = Dense(256, activation='relu')(feature1)\n",
        "\t# feature1 = Dropout(0.25)(feature0)\n",
        "\t# feature1 = Dropout(0.75)(feature0)\n",
        "\t# feature1 = Dropout(0.87)(feature0)\n",
        "\t# feature1 = Dropout(1)(feature0)\n",
        "\t# feature2 = Dense(256, activation='relu')(feature2)\n",
        "\tinputs2 = Input(shape=(max_length,))\n",
        "\tsequence1 = Embedding(word_count, 256, mask_zero=True)(inputs2)\n",
        "\tsequence2 = Dropout(0.5)(sequence1)\n",
        "\tsequence3 = LSTM(256)(sequence2)\n",
        "\tmerge1 = add([feature2, sequence3])\n",
        "\tmerge2 = Dense(256, activation='relu')(merge1)\n",
        "\toutputs = Dense(word_count, activation='softmax')(merge2)\n",
        "\tmodel = Model(inputs=[feature0, inputs2], outputs=outputs)\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\tplot_model(model, to_file='model.png', show_shapes=True)\n",
        "\treturn model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZCVbut8fiNa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training\n",
        "filename = 'Flickr8k_text/Flickr_8k.trainImages.txt'\n",
        "train = dataset_load(filename)\n",
        "print('Training Dataset:', len(train))\n",
        "train_desc = desc_load('descriptions.txt', train)\n",
        "print('Training Descriptions:', len(train_desc))\n",
        "train_features = img_desc('features.pkl', train)\n",
        "print('Training Images: ', len(train_features))\n",
        "token = tokenize(train_desc)\n",
        "word_count = len(token.word_index) + 1\n",
        "print('Total number of Vocabulary words:', word_count)\n",
        "max_length = max_length(train_desc)\n",
        "X1train, X2train, ytrain = caption_generator(token, max_length, train_desc, train_features, word_count)\n",
        "\n",
        "# development\n",
        "filename = 'Flickr8k_text/Flickr_8k.devImages.txt'\n",
        "dev = dataset_load(filename)\n",
        "print('Development Dataset:', len(dev))\n",
        "dev_desc = desc_load('descriptions.txt', dev)\n",
        "print('Development Descriptions:', len(dev_desc))\n",
        "dev_features = img_desc('features.pkl', dev)\n",
        "print('Development Images:', len(dev_features))\n",
        "X1dev, X2dev, ydev = caption_generator(token, max_length, dev_desc, dev_features, word_count)\n",
        "\n",
        "# Fitting the model on the training model\n",
        "model = training_model(word_count, max_length)\n",
        "filepath = 'model-ep{epoch:03d}.h5'\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=2, save_best_only=True, mode='min')\n",
        "history = model.fit([X1train, X2train], ytrain, epochs=10, verbose=1, callbacks=[checkpoint], validation_data=([X1dev, X2dev], ydev))\n",
        "dump(history.history, open('history.pkl', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krMaz1De2WgA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = load(open('history.pkl', 'rb'))\n",
        "history['val_loss']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rwJhl4V2kWN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize_word(result, token):\n",
        "\tfor tok, value in token.word_index.items():\n",
        "\t\tif value == result:\n",
        "\t\t\treturn tok\n",
        "\treturn None\n",
        "\n",
        "# image caption generator\n",
        "def final_caption_generator(model, token, image, max_length):\n",
        "\tstart = 'capstart'\n",
        "\tfor _ in range(max_length):\n",
        "\t\tsequence = token.texts_to_sequences([start])[0]\n",
        "\t\tsequence = pad_sequences([sequence], maxlen=max_length)\n",
        "\t\tyhat = argmax(model.predict([image,sequence], verbose=0))\n",
        "\t\tword = tokenize_word(yhat, token)\n",
        "\t\tif word is None:\n",
        "\t\t\tbreak\n",
        "\t\tstart += ' ' + word\n",
        "\t\tif word == 'capend':\n",
        "\t\t\tbreak\n",
        "\treturn start\n",
        "\n",
        "# get BLEU Scores\n",
        "def bleu_scores(model, caption, images, token, max_length):\n",
        "\tactual, predicted = [], []\n",
        "\tfor key, value in caption.items():\n",
        "\t\tpred = final_caption_generator(model, token, images[key], max_length)\n",
        "\t\tlemma = [val.split() for val in value]\n",
        "\t\tactual.append(lemma)\n",
        "\t\tpredicted.append(pred.split())\n",
        "\tprint('BLEU-1:', corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))\n",
        "\tprint('BLEU-2:', corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0)))\n",
        "\tprint('BLEU-3:', corpus_bleu(actual, predicted, weights=(0.3, 0.3, 0.3, 0)))\n",
        "\tprint('BLEU-4:', corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EFvQ1jP2nHq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# again create token for training\n",
        "filename = 'Flickr8k_text/Flickr_8k.trainImages.txt'\n",
        "train = dataset_load(filename)\n",
        "print('Training Dataset:', len(train))\n",
        "train_desc = desc_load('descriptions.txt', train)\n",
        "print('Training Descriptions:', len(train_desc))\n",
        "token = tokenize(train_desc)\n",
        "word_count = len(token.word_index) + 1\n",
        "print('Total number of Vocabulary words:', word_count)\n",
        "max_length = max_length(train_desc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfPGy3JJ2qvu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#testing\n",
        "filename = 'Flickr8k_text/Flickr_8k.testImages.txt'\n",
        "test = dataset_load(filename)\n",
        "print('Testing Dataset:', len(test))\n",
        "test_desc = desc_load('descriptions.txt', test)\n",
        "print('Testing Descriptions:', len(test_desc))\n",
        "test_features = img_desc('features.pkl', test)\n",
        "print('Testing Images:', len(test_features))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wz_aqaJr2uqM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#getting bleu scores for the best model\n",
        "model = load_model('model-ep002.h5')\n",
        "bleu_scores(model, test_desc, test_features, token, max_length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdxpBN_V2xNR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generating captions for one test image\n",
        "filename = 'Flickr8k_text/Flickr_8k.trainImages.txt'\n",
        "train = dataset_load(filename)\n",
        "print('Training Dataset:', len(train))\n",
        "train_desc = desc_load('descriptions.txt', train)\n",
        "print('Training Descriptions:', len(train_desc))\n",
        "token = tokenize(train_desc)\n",
        "# save the tokenizer\n",
        "dump(token, open('token.pkl', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ho-mAPqs2zw8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# extracting features from one test image\n",
        "def extract_features_of_one(name):\n",
        "\tmodel = VGG16()\n",
        "\t# model = VGG19()\n",
        "\t# model = InceptionV3()\n",
        "\t# model = ResNet50()\n",
        "\t# model = InceptionResNetV2()\n",
        "\t# feature_extractor = InceptionResNetV2(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n",
        "\t# model = feature_extractor.output\n",
        "\t# model = GlobalAveragePooling2D()(model)\n",
        "\t# model = Dropout(0.5)(model)\n",
        "\t# model = Dense(4096, activation=\"relu\")(model)\n",
        "\t# model = Dropout(0.5)(model)\n",
        "\t# model = Dense(4096, activation=\"relu\")(model)\n",
        "\n",
        "\tmodel.layers.pop()\n",
        "\tmodel = Model(inputs=model.inputs, outputs=model.layers[-1].output)\n",
        "\n",
        "\timg = img_to_array(load_img(name, target_size=(224, 224)))\n",
        "\timg = img.reshape((1, img.shape[0], img.shape[1], img.shape[2]))\n",
        "\timg = preprocess_input(img)\n",
        "\tfeature = model.predict(img, verbose=0)\n",
        "\treturn feature"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDG2hFG_22uJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "token = load(open('token.pkl', 'rb'))\n",
        "max_length = max_length(train_desc)\n",
        "model = load_model('model-ep002.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fC7vSUEY247m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load and prepare the photograph\n",
        "image = extract_features_of_one('test_image.jpg')\n",
        "description = final_caption_generator(model, token, image, max_length)\n",
        "print(description.split(' ', 1)[1].rsplit(' ', 1)[0] )"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}